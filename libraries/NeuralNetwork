package MachineLearning.Libraries;

public class NeuralNetwork {
    public double learningRate;
    int layersSizes[];
    Matrix weights[];
    Matrix biases[];

    public NeuralNetwork(int[] lyrs){
        learningRate = 1;
        layersSizes = lyrs;
        weights = new Matrix[layersSizes.length-1];
        biases = new Matrix[layersSizes.length-1];

        // weights and biases init
        for (int i = 0; i < layersSizes.length - 1; i++) {
            weights[i] = new Matrix(layersSizes[i+1], layersSizes[i]);
            weights[i].randomize();

            biases[i] = new Matrix(layersSizes[i+1], 1);
            biases[i].randomize();
        }

        weightsPrint();
    }

    public double[] predict(double[] inputArray) {
        Matrix[] layers = new Matrix[layersSizes.length];
        layers[0] = Matrix.fromArray(inputArray);

        for (int i = 0; i < layersSizes.length - 1; i++) {
            layers[i+1] = Matrix.multiply(weights[i], layers[i]);
            layers[i+1].add(biases[i]);
            layers[i+1].activate();
        }

        return layers[layersSizes.length - 1].toArray();
    }

    public void train(double[] inputArray, double[] targetsArray) {

        // Forward
        Matrix[] layers = new Matrix[layersSizes.length];
        layers[0] = Matrix.fromArray(inputArray);
        Matrix targets = Matrix.fromArray(targetsArray);

        for (int i = 0; i < layersSizes.length - 1; i++) {
            layers[i+1] = Matrix.multiply(weights[i], layers[i]);
            layers[i+1].add(biases[i]);
            layers[i+1].activate();
        }

        // Backpropagation
        Matrix[] errors = new Matrix[layersSizes.length];
        errors[layersSizes.length - 1] = Matrix.sub(targets, layers[layersSizes.length - 1]);
        
        for (int i = layersSizes.length - 1; i > 0; i--) {
            Matrix gradients = Matrix.dActivate(layers[i]);
            gradients = Matrix.mult2(gradients, errors[i]);
            gradients.multScalar(learningRate);
            
            weights[i-1].add(Matrix.multiply(gradients, Matrix.transpose(layers[i - 1])));
            biases[i-1].add(gradients);

            errors[i - 1] = Matrix.multiply(Matrix.transpose(weights[i - 1]), errors[i]);
        }
    }
    
    public NeuralNetwork copy(NeuralNetwork NN) {
        NeuralNetwork NN2 = new NeuralNetwork(NN.layersSizes);

        for (int i = 0; i < layersSizes.length - 1; i++) {
            NN2.weights[i] = NN.weights[i];
            NN2.biases[i] = NN.biases[i];
        }

        NN2.learningRate = NN.learningRate;

        return NN2;
    }

    public void setLearningRate(double rate) {
        learningRate = rate;
    }

    public void mapPrint() {
        for (double i = 0; i < 10; i++) {
            for (double j = 0; j < 10; j++) {
                double[] point = {i/10, j/10};
                System.out.print(Math.round(predict(point)[0]) + " ");
            }
            System.out.println();
        }
        System.out.println();
    }

    public void infoPrint(int training, int guessing, double success, double error) {
        System.out.print("data points: ");
        System.out.println(training);
        System.out.print("learning rate: ");
        System.out.println(learningRate);
        System.out.print("error average: ");
        System.out.println((float)error/guessing);
        System.out.print("success: ");
        System.out.print(success/(guessing/100));
        System.out.println(" %");
        System.out.println();
    }

    public void weightsPrint(){
        System.out.println("inputs to hidden weights:");
        weights[0].print();
        System.out.println("hidden to output weights:");
        weights[1].print();
        System.out.println();
    }
}
